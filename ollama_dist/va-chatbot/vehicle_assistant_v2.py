#!/usr/bin/env python3
"""
è½¦è½½è¯­éŸ³åŠ©æ‰‹ V2 - ä¼˜åŒ–ç‰ˆ
é’ˆå¯¹0.5bå°æ¨¡å‹ä¼˜åŒ–ï¼Œæ”¯æŒå¤šè½®å¯¹è¯å’ŒJSONå·¥å…·è°ƒç”¨
"""

import json
import re
from typing import Any, Dict, Optional, Tuple

from langchain_core.prompts import ChatPromptTemplate
from langchain_ollama.llms import OllamaLLM
from loguru import logger
from prompt_toolkit import prompt
from prompt_toolkit.history import InMemoryHistory


class VehicleAssistant:
    """è½¦è½½è¯­éŸ³åŠ©æ‰‹ä¸»ç±»"""

    # è½¦è¾†åŠŸèƒ½å®šä¹‰
    VEHICLE_FUNCTIONS = {
        "air_switch": "ç©ºè°ƒå¼€å…³",
        "air_volume": "ç©ºè°ƒé£é‡",
        "air_temp": "ç©ºè°ƒæ¸©åº¦",
        "car_window": "è½¦çª—",
        "dms_control": "é©¾é©¶å‘˜æ£€æµ‹",
        "poslgt_control": "ä½ç½®ç¯",
        "hbeam_control": "è¿œå…‰ç¯",
        "lbeam_control": "è¿‘å…‰ç¯",
    }

    # æ“ä½œå®šä¹‰
    OPERATIONS = {
        "open": "æ‰“å¼€",
        "close": "å…³é—­",
        "up": "è°ƒå¤§/è°ƒé«˜",
        "down": "è°ƒå°/è°ƒä½",
    }

    # åªæœ‰è¿™äº›åŠŸèƒ½æ”¯æŒup/downæ“ä½œ
    ADJUSTABLE_FUNCTIONS = {"air_volume", "air_temp", "car_window"}

    def __init__(self, model_name: str = "qwen3:0.6b"):
        """åˆå§‹åŒ–è½¦è½½åŠ©æ‰‹"""
        self.model = OllamaLLM(model=model_name)
        self.vehicle_state = {}  # è½¦è¾†çŠ¶æ€è·Ÿè¸ª
        self.conversation_history = []  # å¯¹è¯å†å²
        self.max_context_length = 3  # æœ€å¤§ä¸Šä¸‹æ–‡è½®æ•°

        # é’ˆå¯¹å°æ¨¡å‹ä¼˜åŒ–çš„çº¦æŸæ€§æç¤ºè¯æ¨¡æ¿ï¼ŒåŠ å…¥äº†ç¤ºä¾‹
        self.template = """ä½ æ˜¯è½¦è½½è¯­éŸ³åŠ©æ‰‹ï¼Œä»»åŠ¡æ˜¯ç²¾ç¡®åœ°å°†ç”¨æˆ·æŒ‡ä»¤è½¬æ¢ä¸ºJSONæ ¼å¼ã€‚

# åŠŸèƒ½åˆ—è¡¨ (veh_object)
- air_switch
- air_volume
- air_temp
- car_window
- dms_control
- poslgt_control
- hbeam_control
- lbeam_control

# æ“ä½œåˆ—è¡¨ (veh_operation)
- open æ‰“å¼€
- close å…³é—­
- up è°ƒå¤§/è°ƒé«˜ (ä»…æ”¯æŒ air_volume, air_temp)
- down è°ƒå°/è°ƒä½ (ä»…æ”¯æŒ air_volume, air_temp)

# è§„åˆ™
1. å¿…é¡»ä»ä¸Šé¢çš„åˆ—è¡¨ä¸­é€‰æ‹© veh_object å’Œ veh_operationã€‚
2. `up` æˆ– `down` æ“ä½œåªèƒ½ç”¨äº `air_volume`, `air_temp`ã€‚
3. å¦‚æœæŒ‡ä»¤æ¨¡ç³Š(å¦‚"å¼€ç¯")ï¼Œä¼˜å…ˆé€‰æ‹©æœ€å¸¸ç”¨çš„ `lbeam_control` (è¿‘å…‰ç¯)ã€‚
4. ç”Ÿæˆä¸€ä¸ªç®€çŸ­å‹å¥½çš„ `u_message` æ¥ç¡®è®¤æ“ä½œã€‚
5. ä¸¥æ ¼æŒ‰ç…§ {{"u_message":"","veh_object":"","veh_operation":""}} æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–æ–‡æœ¬ã€‚

# ç¤ºä¾‹
- ç”¨æˆ·: "æ‰“å¼€è½¦ç¯" -> {{"u_message":"å¥½çš„ï¼Œå·²ä¸ºæ‚¨æ‰“å¼€è¿‘å…‰ç¯ã€‚","veh_object":"lbeam_control","veh_operation":"open"}}
- ç”¨æˆ·: "å…³æ‰å¤§ç¯" -> {{"u_message":"å¥½çš„ï¼Œå·²ä¸ºæ‚¨å…³é—­è¿œå…‰ç¯ã€‚","veh_object":"hbeam_control","veh_operation":"close"}}
- ç”¨æˆ·: "ç©ºè°ƒå¼€å¤§ç‚¹" -> {{"u_message":"å¥½çš„ï¼Œå·²å°†ç©ºè°ƒé£é‡è°ƒå¤§ã€‚","veh_object":"air_volume","veh_operation":"up"}}

# å½“å‰çŠ¶æ€
è½¦è¾†çŠ¶æ€: {vehicle_state}
å¯¹è¯å†å²: {context}

# ç”¨æˆ·æŒ‡ä»¤
ç”¨æˆ·: {question}

# è¾“å‡º
/no_think
"""

        self.prompt = ChatPromptTemplate.from_template(self.template)
        self.chain = self.prompt | self.model

    def _compress_context(self) -> str:
        """å‹ç¼©å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œé€‚åº”å°æ¨¡å‹çš„çŸ­ä¸Šä¸‹æ–‡é™åˆ¶"""
        if not self.conversation_history:
            return ""

        # åªä¿ç•™æœ€è¿‘çš„å‡ è½®å¯¹è¯
        recent_history = self.conversation_history[-self.max_context_length :]

        # å‹ç¼©æ ¼å¼ï¼šUser: æŒ‡ä»¤ -> æ“ä½œç»“æœ
        compressed = []
        for item in recent_history:
            user_input = item.get("user_input", "")
            veh_object = item.get("veh_object", "")
            veh_operation = item.get("veh_operation", "")

            if veh_object and veh_operation:
                compressed.append(f"User: {user_input} -> {veh_object}:{veh_operation}")

        return " | ".join(compressed)

    def _format_vehicle_state(self) -> str:
        """æ ¼å¼åŒ–è½¦è¾†çŠ¶æ€ä¿¡æ¯"""
        if not self.vehicle_state:
            return "æ— "

        state_items = []
        for func, status in self.vehicle_state.items():
            func_name = self.VEHICLE_FUNCTIONS.get(func, func)
            state_items.append(f"{func_name}:{status}")

        return ",".join(state_items)

    def _parse_json_response(self, response: str) -> Optional[Dict[str, Any]]:
        """
        æ›´å¥å£®çš„JSONå“åº”è§£æå™¨ã€‚
        å¯ä»¥å¤„ç† <think> æ ‡ç­¾å’Œ markdown JSON ä»£ç å—ã€‚
        """
        try:
            # 1. ç§»é™¤ think æ ‡ç­¾ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            response = re.sub(
                r"<think>.*?</think>", "", response, flags=re.DOTALL
            ).strip()

            # 2. æŸ¥æ‰¾ markdown JSON å—
            json_match = re.search(
                r"```json\s*(\{.*?\})\s*```", response, flags=re.DOTALL
            )
            json_str = ""
            if json_match:
                json_str = json_match.group(1)
            else:
                # 3. å¦‚æœæ²¡æœ‰ markdown å—ï¼Œç›´æ¥æŸ¥æ‰¾ JSON å¯¹è±¡
                json_match = re.search(r"\{.*\}", response, flags=re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)

            if not json_str:
                logger.warning(f"å“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONéƒ¨åˆ†: {response}")
                return None

            parsed = json.loads(json_str)

            # éªŒè¯å¿…éœ€å­—æ®µåŠå…¶å€¼ä¸ä¸ºç©º
            required_fields = ["u_message", "veh_object", "veh_operation"]
            if all(field in parsed and parsed[field] for field in required_fields):
                return parsed

            logger.warning(f"è§£æåçš„JSONç¼ºå°‘å¿…è¦å­—æ®µæˆ–å­—æ®µå€¼ä¸ºç©º: {parsed}")
            return None

        except json.JSONDecodeError:
            # åœ¨è§£æå¤±è´¥æ—¶ï¼Œè®°å½•ä¸‹å‡†å¤‡è§£æçš„å­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿è°ƒè¯•
            logger.error(f"JSONè§£æé”™è¯¯, åŸå§‹å­—ç¬¦ä¸²: '{json_str}'")
            return None
        except Exception as e:
            logger.error(f"è§£æå“åº”æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}, å“åº”: {response}")
            return None

    def _validate_command(self, veh_object: str, veh_operation: str) -> bool:
        """éªŒè¯æŒ‡ä»¤çš„æœ‰æ•ˆæ€§"""
        # æ£€æŸ¥åŠŸèƒ½æ˜¯å¦å­˜åœ¨
        if veh_object not in self.VEHICLE_FUNCTIONS:
            logger.warning(f"æœªçŸ¥çš„è½¦è¾†åŠŸèƒ½: {veh_object}")
            return False

        # æ£€æŸ¥æ“ä½œæ˜¯å¦å­˜åœ¨
        if veh_operation not in self.OPERATIONS:
            logger.warning(f"æœªçŸ¥çš„æ“ä½œ: {veh_operation}")
            return False

        # æ£€æŸ¥up/downæ“ä½œæ˜¯å¦åªç”¨äºå¯è°ƒèŠ‚åŠŸèƒ½
        if (
            veh_operation in ["up", "down"]
            and veh_object not in self.ADJUSTABLE_FUNCTIONS
        ):
            logger.warning(f"åŠŸèƒ½ {veh_object} ä¸æ”¯æŒ {veh_operation} æ“ä½œ")
            return False

        return True

    def _update_vehicle_state(self, veh_object: str, veh_operation: str):
        """æ›´æ–°è½¦è¾†çŠ¶æ€"""
        if veh_operation == "open":
            self.vehicle_state[veh_object] = "å¼€å¯"
        elif veh_operation == "close":
            self.vehicle_state[veh_object] = "å…³é—­"
        elif veh_operation == "up":
            current = self.vehicle_state.get(veh_object, "ä¸­ç­‰")
            if current == "ä½":
                self.vehicle_state[veh_object] = "ä¸­ç­‰"
            else:
                self.vehicle_state[veh_object] = "é«˜"
        elif veh_operation == "down":
            current = self.vehicle_state.get(veh_object, "ä¸­ç­‰")
            if current == "é«˜":
                self.vehicle_state[veh_object] = "ä¸­ç­‰"
            else:
                self.vehicle_state[veh_object] = "ä½"

    def process_command(self, user_input: str) -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·æŒ‡ä»¤"""
        try:
            # å‡†å¤‡ä¸Šä¸‹æ–‡
            context = self._compress_context()
            vehicle_state = self._format_vehicle_state()

            # è°ƒç”¨æ¨¡å‹ (æµå¼)
            stream = self.chain.stream(
                {
                    "context": context,
                    "vehicle_state": vehicle_state,
                    "question": user_input,
                }
            )

            print("ğŸ¤– åŠ©æ‰‹: ", end="", flush=True)
            response = ""
            for chunk in stream:
                print(chunk, end="", flush=True)
                response += chunk
            print()  # Newline after stream ends

            logger.info(f"æ¨¡å‹åŸå§‹å“åº”: {response}")

            # è§£æJSON
            parsed_response = self._parse_json_response(response)

            if parsed_response:
                veh_object = parsed_response["veh_object"]
                veh_operation = parsed_response["veh_operation"]
                u_message = parsed_response["u_message"]

                # éªŒè¯æŒ‡ä»¤
                if self._validate_command(veh_object, veh_operation):
                    # æ›´æ–°çŠ¶æ€
                    self._update_vehicle_state(veh_object, veh_operation)

                    # è®°å½•å¯¹è¯å†å²
                    self.conversation_history.append(
                        {
                            "user_input": user_input,
                            "veh_object": veh_object,
                            "veh_operation": veh_operation,
                            "u_message": u_message,
                        }
                    )

                    # é™åˆ¶å†å²è®°å½•é•¿åº¦
                    if len(self.conversation_history) > self.max_context_length:
                        self.conversation_history.pop(0)

                    return {
                        "response": u_message,
                        "tool_call": parsed_response,
                        "success": True,
                    }
                else:
                    error_msg = "æŠ±æ­‰ï¼Œæˆ‘ä¸ç†è§£è¿™ä¸ªæŒ‡ä»¤ï¼Œè¯·å†è¯•ä¸€æ¬¡ï½"
                    # æµå¼è¾“å‡ºå¯èƒ½å·²ç»è¾“å‡ºäº†éƒ¨åˆ†å†…å®¹ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œè¡¥å…¨ä¸€å¥æç¤º
                    # æ‰“å°ä¸€ä¸ªæ¢è¡Œç¬¦æ¥åˆ†éš”é”™è¯¯çš„æµå¼è¾“å‡ºå’Œæˆ‘ä»¬çš„é”™è¯¯ä¿¡æ¯
                    print(f"ğŸ¤– åŠ©æ‰‹: {error_msg}")
                    return {
                        "response": error_msg,
                        "tool_call": None,
                        "success": False,
                    }
            else:
                error_msg = "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·å†è¯•ä¸€æ¬¡ï½"
                # åŒæ ·ï¼Œåœ¨æµå¼è¾“å‡ºåè¡¥å……é”™è¯¯ä¿¡æ¯
                print(f"ğŸ¤– åŠ©æ‰‹: {error_msg}")
                return {
                    "response": error_msg,
                    "tool_call": None,
                    "success": False,
                }

        except Exception as e:
            logger.error(f"å¤„ç†æŒ‡ä»¤æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            error_msg = "ç³»ç»Ÿå‡ºç°é”™è¯¯ï¼Œè¯·ç¨åå†è¯•ï½"
            print(f"ğŸ¤– åŠ©æ‰‹: {error_msg}")
            return {
                "response": error_msg,
                "tool_call": None,
                "success": False,
            }

    def _warmup_model(self):
        """é¢„çƒ­æ¨¡å‹ï¼Œå‡å°‘é¦–æ¬¡å“åº”å»¶è¿Ÿ"""
        logger.info("æ­£åœ¨é¢„çƒ­æ¨¡å‹ï¼Œè¯·ç¨å€™...")
        try:
            # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„ã€é€šç”¨çš„æç¤ºè¯æ¥é¢„çƒ­
            self.model.invoke("ä½ å¥½")
            logger.info("âœ… æ¨¡å‹é¢„çƒ­å®Œæˆï¼")
        except Exception as e:
            logger.error(f"æ¨¡å‹é¢„çƒ­å¤±è´¥: {e}")

    def start_conversation(self):
        """å¯åŠ¨å¯¹è¯å¾ªç¯"""
        logger.info("ğŸš— è½¦è½½è¯­éŸ³åŠ©æ‰‹å·²å¯åŠ¨ï¼")
        logger.info("æ”¯æŒçš„åŠŸèƒ½ï¼šç©ºè°ƒã€è½¦çª—ã€ç¯å…‰æ§åˆ¶ç­‰")
        logger.info("æç¤º: ä½¿ç”¨ â†‘ å’Œ â†“ ç®­å¤´å¯ä»¥æµè§ˆå†å²æŒ‡ä»¤ã€‚")
        logger.info("è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º")
        logger.info("-" * 50)

        history = InMemoryHistory()

        while True:
            try:
                user_input = prompt("\nğŸ¤ æ‚¨: ", history=history).strip()

                if user_input.lower() in ["exit", "quit", "bye", "é€€å‡º"]:
                    logger.info("ğŸ‘‹ å†è§ï¼ç¥æ‚¨è¡Œè½¦æ„‰å¿«ï¼")
                    break

                if not user_input:
                    continue

                # å¤„ç†æŒ‡ä»¤ (ç°åœ¨ process_command ä¼šè‡ªå·±æ‰“å°æµå¼å“åº”)
                result = self.process_command(user_input)

                # ä»…åœ¨æˆåŠŸæ—¶æ˜¾ç¤ºå·¥å…·è°ƒç”¨å’ŒçŠ¶æ€
                if result["success"]:
                    if result["tool_call"]:
                        tool_call = result["tool_call"]
                        print(
                            f"ğŸ”§ å·¥å…·è°ƒç”¨: {tool_call['veh_object']} -> {tool_call['veh_operation']}"
                        )

                    # æ˜¾ç¤ºå½“å‰çŠ¶æ€
                    if self.vehicle_state:
                        print(f"ğŸ“Š å½“å‰çŠ¶æ€: {self._format_vehicle_state()}")

            except KeyboardInterrupt:
                logger.info("\nğŸ‘‹ å†è§ï¼ç¥æ‚¨è¡Œè½¦æ„‰å¿«ï¼")
                break
            except Exception as e:
                logger.error(f"å¯¹è¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                print("ğŸ¤– åŠ©æ‰‹: ç³»ç»Ÿå‡ºç°é”™è¯¯ï¼Œè¯·ç¨åå†è¯•ï½")


def main():
    """ä¸»å‡½æ•°"""
    assistant = VehicleAssistant()
    assistant._warmup_model()
    assistant.start_conversation()


if __name__ == "__main__":
    main()
