# è½¦è½½è¯­éŸ³åŠ©æ‰‹ Ollama ä½¿ç”¨è¯´æ˜

## ğŸ“‹ å‰ç½®è¦æ±‚

ç¡®ä¿å·²å®‰è£… [Ollama](https://ollama.com/)ï¼š
```bash
# æ£€æŸ¥ollamaæ˜¯å¦å®‰è£…
ollama --version
```

## âš ï¸ é‡è¦è¯´æ˜

### æ¨¡å‹å‘½åè§„èŒƒ
- Ollama æ¨¡å‹åç§°**ä¸æ”¯æŒä¸­æ–‡å­—ç¬¦**ï¼Œå¿…é¡»ä½¿ç”¨è‹±æ–‡
- åªèƒ½åŒ…å«å°å†™å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦ `-` å’Œä¸‹åˆ’çº¿ `_`
- æ¨èå‘½åï¼š`vehicle-assistant`ã€`car-voice-helper` ç­‰

### è·¨å¹³å°å…¼å®¹æ€§
- âœ… **å®Œå…¨æ”¯æŒè·¨å¹³å°**ï¼šåœ¨ x86 ä¸»æœºåˆ›å»ºçš„æ¨¡å‹å¯ä»¥ç›´æ¥åœ¨ ARM è®¾å¤‡ä¸Šè¿è¡Œ
- âœ… **è‡ªåŠ¨æ¶æ„é€‚é…**ï¼šOllama ä¼šè‡ªåŠ¨ä¸‹è½½é€‚åˆç›®æ ‡æ¶æ„çš„æ¨¡å‹æƒé‡
- âœ… **é…ç½®æ–‡ä»¶é€šç”¨**ï¼šModelfile åœ¨ä¸åŒæ¶æ„é—´å®Œå…¨å…¼å®¹

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åˆ›å»ºæ¨¡å‹

å°† `è½¦è½½è¯­éŸ³åŠ©æ‰‹.Modelfile` ä¿å­˜åˆ°æœ¬åœ°ï¼Œç„¶åæ‰§è¡Œï¼š

```bash
# åˆ›å»ºè½¦è½½è¯­éŸ³åŠ©æ‰‹æ¨¡å‹ï¼ˆæ³¨æ„ï¼šæ¨¡å‹åç§°å¿…é¡»ä½¿ç”¨è‹±æ–‡ï¼‰
ollama create vehicle-assistant -f è½¦è½½è¯­éŸ³åŠ©æ‰‹.Modelfile
```

### 2. è¿è¡Œæ¨¡å‹

```bash
# å¯åŠ¨è½¦è½½è¯­éŸ³åŠ©æ‰‹
ollama run vehicle-assistant
```

### 3. æµ‹è¯•ä½¿ç”¨

æ¨¡å‹å¯åŠ¨åï¼Œå¯ä»¥ç›´æ¥è¾“å…¥è½¦è¾†æ§åˆ¶æŒ‡ä»¤ï¼š

```
>>> æŠŠç©ºè°ƒæ‰“å¼€
{"u_message":"å—–â€”â€”ç©ºè°ƒå·²ç»å¯åŠ¨å•¦ï¼å‡‰é£æ­£å¾€ä½ è¿™è¾¹å¹å‘¢ï¼Œæ„Ÿè§‰å¦‚ä½•ï¼Ÿ","veh_object":"air_switch","veh_operation":"open"}

>>> ç©ºè°ƒå¼€å¤§ç‚¹
{"u_message":"å¥½çš„å¥½çš„ï¼Œé£é‡å·²ç»è°ƒå¤§å•¦ï¼ç°åœ¨æ›´å‡‰çˆ½äº†ï½","veh_object":"air_volume","veh_operation":"up"}

>>> æ¸©åº¦è°ƒé«˜ç‚¹
{"u_message":"å¥½çš„å¥½çš„ï¼Œç©ºè°ƒæ¸©åº¦å·²ç»è°ƒé«˜ï¼Œç°åœ¨åº”è¯¥æ›´èˆ’æœäº†ï¼Œæ˜¯ä¸æ˜¯æš–æ´‹æ´‹çš„ï¼Ÿ","veh_object":"air_temp","veh_operation":"up"}
```

## ğŸ¯ æ”¯æŒçš„åŠŸèƒ½

### ç©ºè°ƒæ§åˆ¶
- "æŠŠç©ºè°ƒæ‰“å¼€" â†’ æ‰“å¼€ç©ºè°ƒ
- "å…³é—­ç©ºè°ƒ" â†’ å…³é—­ç©ºè°ƒ
- "ç©ºè°ƒå¼€å¤§ç‚¹" â†’ è°ƒå¤§é£é‡
- "ç©ºè°ƒå¼€å°ç‚¹" â†’ è°ƒå°é£é‡
- "æ¸©åº¦è°ƒé«˜ç‚¹" â†’ è°ƒé«˜æ¸©åº¦
- "æ¸©åº¦è°ƒä½ç‚¹" â†’ è°ƒä½æ¸©åº¦

### è½¦çª—æ§åˆ¶
- "æ‰“å¼€è½¦çª—" â†’ æ‰“å¼€è½¦çª—
- "å…³é—­è½¦çª—" â†’ å…³é—­è½¦çª—
- "è½¦çª—å‡èµ·æ¥" â†’ è½¦çª—ä¸Šå‡
- "è½¦çª—é™ä¸‹å»" â†’ è½¦çª—ä¸‹é™

### ç¯å…‰æ§åˆ¶
- "æ‰“å¼€è¿œå…‰ç¯" â†’ æ‰“å¼€è¿œå…‰ç¯
- "å…³é—­è¿œå…‰ç¯" â†’ å…³é—­è¿œå…‰ç¯
- "å¼€å¯è¿‘å…‰ç¯" â†’ æ‰“å¼€è¿‘å…‰ç¯
- "å…³é—­è¿‘å…‰ç¯" â†’ å…³é—­è¿‘å…‰ç¯

## ğŸ“ è¾“å‡ºæ ¼å¼

æ‰€æœ‰å“åº”éƒ½é‡‡ç”¨æ ‡å‡†JSONæ ¼å¼ï¼š

```json
{
  "u_message": "ç»™ç”¨æˆ·çš„å‹å¥½å›å¤",
  "veh_object": "è½¦è¾†åŠŸèƒ½æ ‡è¯†",
  "veh_operation": "æ“ä½œæŒ‡ä»¤"
}
```

### åŠŸèƒ½æ ‡è¯† (veh_object)
- `air_switch`: ç©ºè°ƒå¼€å…³
- `air_volume`: ç©ºè°ƒé£é‡
- `air_temp`: ç©ºè°ƒæ¸©åº¦
- `car_window`: è½¦çª—æ§åˆ¶
- `dms_control`: é©¾é©¶å‘˜çŠ¶æ€æ£€æµ‹
- `poslgt_control`: ä½ç½®ç¯
- `hbeam_control`: è¿œå…‰ç¯
- `lbeam_control`: è¿‘å…‰ç¯

### æ“ä½œæŒ‡ä»¤ (veh_operation)
- `open`: æ‰“å¼€/å¯åŠ¨
- `close`: å…³é—­/åœæ­¢
- `up`: è°ƒå¤§/è°ƒé«˜/å‡èµ·
- `down`: è°ƒå°/è°ƒä½/é™ä¸‹

## ğŸ”§ æ¨¡å‹å‚æ•°è¯´æ˜

é’ˆå¯¹ `qwen2.5:0.5b` æ¨¡å‹çš„ä¼˜åŒ–å‚æ•°ï¼š

- `temperature: 0.2` - é™ä½åˆ›é€ æ€§ï¼Œæé«˜ä¸€è‡´æ€§
- `top_p: 0.7` - å‡å°‘éšæœºæ€§
- `top_k: 30` - é™åˆ¶å€™é€‰è¯æ•°é‡
- `num_ctx: 2048` - ä¸Šä¸‹æ–‡çª—å£å¤§å°
- `num_predict: 128` - æœ€å¤§é¢„æµ‹tokensæ•°

## ğŸ› ï¸ é«˜çº§ç”¨æ³•

### é€šè¿‡APIè°ƒç”¨

```bash
# ä½¿ç”¨ollama API
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "vehicle-assistant",
    "prompt": "æŠŠç©ºè°ƒæ‰“å¼€",
    "stream": false
  }'
```

### é›†æˆåˆ°åº”ç”¨

```python
import requests
import json

def call_voice_assistant(user_input):
    response = requests.post('http://localhost:11434/api/generate', 
                           json={
                               'model': 'vehicle-assistant',
                               'prompt': user_input,
                               'stream': False
                           })
    
    if response.status_code == 200:
        result = response.json()
        return json.loads(result['response'])
    return None

# ä½¿ç”¨ç¤ºä¾‹
result = call_voice_assistant("æŠŠç©ºè°ƒæ‰“å¼€")
print(result)
```

## ğŸš« å¸¸è§é—®é¢˜

### Q: åˆ›å»ºæ¨¡å‹æ—¶æç¤º "Error: invalid model name" æ€ä¹ˆåŠï¼Ÿ
A: è¿™æ˜¯å› ä¸ºä½¿ç”¨äº†ä¸­æ–‡å­—ç¬¦ä½œä¸ºæ¨¡å‹åç§°ã€‚è¯·ä½¿ç”¨è‹±æ–‡åç§°ï¼š
```bash
# âŒ é”™è¯¯
ollama create è½¦è½½åŠ©æ‰‹ -f è½¦è½½è¯­éŸ³åŠ©æ‰‹.Modelfile

# âœ… æ­£ç¡®
ollama create vehicle-assistant -f è½¦è½½è¯­éŸ³åŠ©æ‰‹.Modelfile
```

### Q: æç¤º "gathering model components" åå‡ºé”™æ€ä¹ˆåŠï¼Ÿ
A: é€šå¸¸æ˜¯åŸºç¡€æ¨¡å‹ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ‹‰å–åŸºç¡€æ¨¡å‹ï¼š
```bash
ollama pull qwen2.5:0.5b
```

### Q: æ¨¡å‹è¾“å‡ºæ ¼å¼ä¸æ­£ç¡®æ€ä¹ˆåŠï¼Ÿ
A: ç¡®ä¿ä½¿ç”¨äº†å®Œæ•´çš„ Modelfileï¼Œç‰¹åˆ«æ˜¯ MESSAGE ç¤ºä¾‹å¯¹è¯éƒ¨åˆ†ã€‚

### Q: æ¨¡å‹ç†è§£ä¸å‡†ç¡®æ€ä¹ˆåŠï¼Ÿ
A: å¯ä»¥å°è¯•è°ƒæ•´ temperature å‚æ•°ï¼Œæˆ–è€…å¢åŠ æ›´å¤š MESSAGE ç¤ºä¾‹ã€‚

### Q: å¦‚ä½•æ·»åŠ æ–°çš„è½¦è¾†åŠŸèƒ½ï¼Ÿ
A: ä¿®æ”¹ SYSTEM æç¤ºè¯ä¸­çš„åŠŸèƒ½é€‰é¡¹ï¼Œå¹¶æ·»åŠ ç›¸åº”çš„ MESSAGE ç¤ºä¾‹ã€‚

### Q: åœ¨ARMè®¾å¤‡ä¸Šä½¿ç”¨æ˜¯å¦éœ€è¦é‡æ–°åˆ›å»ºæ¨¡å‹ï¼Ÿ
A: ä¸éœ€è¦ã€‚å°† Modelfile å¤åˆ¶åˆ° ARM è®¾å¤‡åé‡æ–°æ‰§è¡Œ create å‘½ä»¤å³å¯ï¼ŒOllama ä¼šè‡ªåŠ¨å¤„ç†æ¶æ„å·®å¼‚ã€‚

## ğŸ”§ æ•…éšœæ’é™¤

### å¿«é€Ÿè¯Šæ–­å‘½ä»¤
```bash
# 1. æ£€æŸ¥ Ollama ç‰ˆæœ¬
ollama --version

# 2. æ£€æŸ¥å¯ç”¨æ¨¡å‹
ollama list

# 3. æ‹‰å–åŸºç¡€æ¨¡å‹
ollama pull qwen2.5:0.5b

# 4. åˆ›å»ºè‡ªå®šä¹‰æ¨¡å‹
ollama create vehicle-assistant -f è½¦è½½è¯­éŸ³åŠ©æ‰‹.Modelfile

# 5. éªŒè¯æ¨¡å‹è¿è¡Œ
ollama run vehicle-assistant

# 6. æµ‹è¯•APIæ¥å£
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "vehicle-assistant", "prompt": "æµ‹è¯•", "stream": false}'
```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®
- **ARMè®¾å¤‡**ï¼šå»ºè®®è°ƒæ•´ `num_thread` å‚æ•°é€‚é…CPUæ ¸å¿ƒæ•°
- **å†…å­˜å—é™**ï¼šå¯ä»¥è€ƒè™‘ä½¿ç”¨æ›´å°çš„æ¨¡å‹æˆ–è°ƒæ•´ `num_ctx` å‚æ•°
- **å“åº”é€Ÿåº¦**ï¼šé™ä½ `temperature` å€¼å¯ä»¥æé«˜å“åº”ä¸€è‡´æ€§

## ğŸ“š ç›¸å…³èµ„æº

- [Ollamaå®˜æ–¹æ–‡æ¡£](https://ollama.readthedocs.io/)
- [Modelfileå‚è€ƒ](https://ollama.readthedocs.io/en/modelfile/)
- [Qwen2.5æ¨¡å‹ä¿¡æ¯](https://ollama.com/library/qwen2.5)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤æ”¹è¿›å»ºè®®å’Œé—®é¢˜æŠ¥å‘Šï¼

## ğŸŒ åå°æœåŠ¡é…ç½®

### OpenAI API å…¼å®¹æ€§
Ollama å®Œå…¨æ”¯æŒ OpenAI å…¼å®¹çš„ API æ¥å£ï¼Œå¯ä»¥æ— ç¼æ›¿ä»£ OpenAI APIï¼š

```bash
# OpenAI å…¼å®¹ç«¯ç‚¹
http://localhost:11434/v1/chat/completions

# åŸç”Ÿ API ç«¯ç‚¹
http://localhost:11434/api/generate
```

### å¯åŠ¨åå°æœåŠ¡
```bash
# å¯åŠ¨æœåŠ¡
ollama serve

# åå°è¿è¡Œ
nohup ollama serve > ollama.log 2>&1 &
```

### ç½‘ç»œé…ç½®
```bash
# é…ç½®ç½‘ç»œè®¿é—®ï¼ˆå…è®¸å‰ç«¯è°ƒç”¨ï¼‰
export OLLAMA_HOST="0.0.0.0"
export OLLAMA_ORIGINS="*"

# é‡å¯æœåŠ¡
sudo systemctl restart ollama
```

### å‰ç«¯é›†æˆç¤ºä¾‹
```javascript
// JavaScript è°ƒç”¨ç¤ºä¾‹
const response = await fetch('http://localhost:11434/v1/chat/completions', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    model: 'vehicle-assistant',
    messages: [{ role: 'user', content: 'å¸®æˆ‘æ‰“å¼€ç©ºè°ƒ' }],
    stream: false
  })
});

const data = await response.json();
console.log(data.choices[0].message.content);
```

**è¯¦ç»†çš„åå°æœåŠ¡é…ç½®è¯·å‚è€ƒï¼š`Ollamaåå°æœåŠ¡é…ç½®æŒ‡å—.md`**

---

*åŸºäº qwen2:0.5b æ¨¡å‹æ„å»ºï¼Œé’ˆå¯¹è½¦è½½è¯­éŸ³åŠ©æ‰‹åœºæ™¯ä¼˜åŒ–*  
*æ¨¡å‹åç§°ï¼švehicle-assistantï¼ˆéµå¾ª Ollama è‹±æ–‡å‘½åè§„èŒƒï¼‰*  
*æ”¯æŒè·¨å¹³å°éƒ¨ç½²ï¼šx86ã€ARM æ¶æ„å®Œå…¨å…¼å®¹*  
*æ”¯æŒ OpenAI API å…¼å®¹æ¥å£ï¼Œä¾¿äºå‰ç«¯é›†æˆ* 